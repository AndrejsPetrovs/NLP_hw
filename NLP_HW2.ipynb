{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NLP Homework 2"
      ],
      "metadata": {
        "id": "m--mo9Arfwle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/AndrejsPetrovs/NLP_hw/main/dev.tsv\n",
        "!wget https://raw.githubusercontent.com/AndrejsPetrovs/NLP_hw/main/ekman_mapping.json\n",
        "!wget https://raw.githubusercontent.com/AndrejsPetrovs/NLP_hw/main/emotions.txt\n",
        "!wget https://raw.githubusercontent.com/AndrejsPetrovs/NLP_hw/main/stoplist.txt\n",
        "!wget https://raw.githubusercontent.com/AndrejsPetrovs/NLP_hw/main/test.tsv\n",
        "!wget https://raw.githubusercontent.com/AndrejsPetrovs/NLP_hw/main/train.tsv"
      ],
      "metadata": {
        "id": "eHeDvtMUfmSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install scikit-learn\n",
        "!pip install seaborn"
      ],
      "metadata": {
        "id": "B6_3mlU1gU_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import numpy\n",
        "\n",
        "import seaborn\n",
        "import matplotlib.pyplot as mplot\n",
        "\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import datetime\n",
        "import json\n",
        "import csv\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "oy_4XkalgaDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Script to create emotion mappings and new data files"
      ],
      "metadata": {
        "id": "DGzCNTeFgpj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map emotions to numbers according to emotions.txt file\n",
        "emotions = []\n",
        "with open(\"emotions.txt\") as f:\n",
        "    for row in f:\n",
        "        if(row[-1]==\"\\n\"):\n",
        "            row=row[:-1]\n",
        "        emotions+=[row]\n",
        "\n",
        "targets=[\"dev.tsv\", \"test.tsv\", \"train.tsv\"]\n",
        "targetsout=[\"dev2.tsv\", \"test2.tsv\", \"train2.tsv\"]\n",
        "\n",
        "# Map emotions according to ekman_mapping.json file\n",
        "mappingfile=\"ekman_mapping.json\"\n",
        "with open(mappingfile) as f:\n",
        "    mappingwords=json.load(f)\n",
        "mapping=[0]*28\n",
        "mapping[27]=6\n",
        "\n",
        "classes=[\"\"]*7\n",
        "classes[6]=\"neutral\"\n",
        "wnum=0\n",
        "for w in mappingwords:\n",
        "    classes[wnum]=w\n",
        "    for w2 in mappingwords[w]:\n",
        "        mapping[emotions.index(w2)]=wnum\n",
        "    wnum+=1\n",
        "\n",
        "for i in range(len(classes)):\n",
        "    print(f\"{i}: {classes[i]}\")\n",
        "\n",
        "\n",
        "alltxt = \"\"\n",
        "\n",
        "# Create new data files according to the mapping and format\n",
        "for i in range(len(targets)):\n",
        "    with open(targets[i], encoding=\"utf8\") as fin:\n",
        "        with open(targetsout[i], \"w\", encoding=\"utf8\") as fout:\n",
        "            reader = csv.reader(fin, delimiter=\"\\t\")\n",
        "            writer = csv.writer(fout, delimiter=\"\\t\", lineterminator=\"\\n\")\n",
        "            for row in reader:\n",
        "                txt = row[0]\n",
        "                if i==1:\n",
        "                    alltxt+=(txt+\" \")\n",
        "                # Write multiple rows if a piece of text has many tags, but make sure that they map to different emotions\n",
        "                tags = row[1].split(\",\")\n",
        "                for j in range(len(tags)):\n",
        "                    tags[j]=mapping[int(tags[j])]\n",
        "                tags=list(set(tags))\n",
        "                for tag in tags:\n",
        "                    writer.writerow([str(tag), txt])\n"
      ],
      "metadata": {
        "id": "IwvgVFHIgx0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for text preprocessing, taken from https://github.com/LUMII-AILab/NLP_Course/blob/main/notebooks/NaiveBayes.ipynb"
      ],
      "metadata": {
        "id": "HzffnaK6lHLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(text):\n",
        "\ttext = text.lower()\n",
        "\ttext = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', text) # e-mail addresses\n",
        "\ttext = re.sub(r'https?://[A-Za-z0-9./-]+|www\\.[A-Za-z0-9./-]+', '', text)\t\t\t\t# URLs\n",
        "\ttext = re.sub(r'\\d+', \"100\", text)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    # numbers\n",
        "\n",
        "\treturn text.strip()\n",
        "\n",
        "\n",
        "def normalize_vector(vector):\n",
        "\twords = list(vector.keys())\n",
        "\n",
        "\tfor w in words:\n",
        "\t\tif w in STOPLIST or len(w) == 1 or w not in WHITELIST:\n",
        "\t\t\tvector.pop(w)\n",
        "\n",
        "\treturn vector\n",
        "\n",
        "\n",
        "def vectorize_text(text):\n",
        "\treturn normalize_vector({word: True for word in nltk.word_tokenize(normalize_text(text))})"
      ],
      "metadata": {
        "id": "2TeZqmd2llWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Script for word frequency list creation"
      ],
      "metadata": {
        "id": "yNh8cbgnmAjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create word frequency file using nltk\n",
        "alltxt = normalize_text(alltxt)\n",
        "\n",
        "allsents = sent_tokenize(alltxt)\n",
        "freqlist = {}\n",
        "for s in allsents:\n",
        "    s = re.sub(r'\\s+', ' ', s.strip())\n",
        "    w = word_tokenize(s)\n",
        "    for word in w:\n",
        "        word=word.lower()\n",
        "        if word not in freqlist:\n",
        "            freqlist[word]=0\n",
        "        freqlist[word]+=1\n",
        "\n",
        "\n",
        "freqlistfile = \"freqlist.tsv\"\n",
        "\n",
        "\n",
        "with open(freqlistfile, \"w\", encoding=\"utf8\") as f:\n",
        "    writer = csv.writer(f, delimiter=\"\\t\", lineterminator=\"\\n\")\n",
        "    for word in freqlist.keys():\n",
        "        writer.writerow([str(freqlist[word]), word])\n",
        "\n"
      ],
      "metadata": {
        "id": "ikdYALSfl9eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More code for preprocessing from the example"
      ],
      "metadata": {
        "id": "wJdJgMKQmP7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialise(stop_txt, freq_tsv):\n",
        "\tglobal STOPLIST\n",
        "\tSTOPLIST = set()\n",
        "\n",
        "\twith open(stop_txt) as txt:\n",
        "\t\tfor word in txt:\n",
        "\t\t\tSTOPLIST.add(normalize_text(word.strip()))\n",
        "\n",
        "\tprint(\"[I] Word stoplist is read:\", len(STOPLIST))\n",
        "\n",
        "\tglobal WHITELIST\n",
        "\tWHITELIST = set()\n",
        "\n",
        "\twith open(freq_tsv) as tsv:\n",
        "\t\tfor entry in tsv:\n",
        "\t\t\tfreq, word = entry.strip().split(\"\\t\")\n",
        "\n",
        "\t\t\tif int(freq) < 5: # Could also be 6 or 7 with minimal effect\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\t\tWHITELIST.add(normalize_text(word))\n",
        "\n",
        "\tprint(\"[I] Word whitelist is read:\", len(WHITELIST))"
      ],
      "metadata": {
        "id": "WLi-W7bWlXSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5-7 minimum word repetition threshold seems to give the best accuracy"
      ],
      "metadata": {
        "id": "ozeuxhooqTrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(file):\n",
        "\tdata_set = {}  # topic => samples\n",
        "\n",
        "\twith open(file) as data:\n",
        "\t\tfor entry in data:\n",
        "\t\t\ttopic, text = entry.strip().split(\"\\t\")\n",
        "\n",
        "\t\t\tsub_set = []\n",
        "\t\t\tif topic in data_set:\n",
        "\t\t\t\tsub_set = data_set[topic]\n",
        "\n",
        "\t\t\tsub_set.append((vectorize_text(text), topic))\n",
        "\t\t\tdata_set[topic] = sub_set\n",
        "\n",
        "\treturn data_set\n",
        "\n",
        "\n",
        "def join_data(data_set):\n",
        "\tunion = []\n",
        "\n",
        "\tfor cat in data_set:\n",
        "\t\tunion += data_set[cat]\n",
        "\n",
        "\treturn union"
      ],
      "metadata": {
        "id": "otTc3gtxmZSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for machine learning model evaluation. The base taken from the example, adapted for having separate train and test data sets"
      ],
      "metadata": {
        "id": "qjw2FMfimfhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validate2(train_data_set, test_data_set):\n",
        "    global LABELS\n",
        "    LABELS = []\n",
        "\n",
        "    train_data = numpy.array([])\n",
        "    test_data = numpy.array([])\n",
        "\n",
        "\n",
        "    for cat in train_data_set:\n",
        "        LABELS.append(cat)\n",
        "        if len(train_data) > 0:\n",
        "            train_data = numpy.append(train_data, train_data_set[cat], axis=0)\n",
        "        else:\n",
        "            train_data = train_data_set[cat]\n",
        "\n",
        "\n",
        "    for cat in test_data_set:\n",
        "        if len(test_data) > 0:\n",
        "            test_data = numpy.append(test_data, test_data_set[cat], axis=0)\n",
        "        else:\n",
        "            test_data = test_data_set[cat]\n",
        "\n",
        "    # Naive Bayes classifier: training and evaluation\n",
        "    nb = nltk.NaiveBayesClassifier.train(train_data)\n",
        "    validation_accuracy = nltk.classify.accuracy(nb, test_data)\n",
        "\n",
        "    validations = [validation_accuracy]\n",
        "    gold_result = []\n",
        "    silver_result = []\n",
        "\n",
        "    for t in test_data:\n",
        "        gold_result.append(t[1])\n",
        "        silver_result.append(nb.classify(t[0]))\n",
        "\n",
        "    return (validations, gold_result, silver_result)"
      ],
      "metadata": {
        "id": "_k7BlXEdmuof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_validation2(train_data_path, test_data_path):\n",
        "\t\tprint(\"Cross-validation:\\n\")\n",
        "\n",
        "\t\tstart_time = datetime.datetime.now().replace(microsecond=0)\n",
        "\n",
        "\t\t# Run cross-validation\n",
        "\t\tvalidations, gold, silver = cross_validate2(read_data(train_data_path), read_data(test_data_path))\n",
        "\n",
        "\t\t# Print the average accuracy: for each cross-validation step, and overall\n",
        "\t\tfor step in validations:\n",
        "\t\t\t\tprint(\"{0:.2f}  \".format(step), end='')\n",
        "\t\tprint(\"{0:.0%}\".format(numpy.mean(validations)))\n",
        "\n",
        "\t\tend_time = datetime.datetime.now().replace(microsecond=0)\n",
        "\t\tprint(\"\\nTotal validation time:\", end_time - start_time, \"\\n\")\n",
        "\n",
        "\t\t# Print an evaluation report\n",
        "\t\tprint(classification_report(gold, silver))\n",
        "\n",
        "\t\t# Print a fancy confusion matrix\n",
        "\t\tmatrix = confusion_matrix(gold, silver)\n",
        "\t\tseaborn.heatmap(matrix, xticklabels=LABELS, yticklabels=LABELS)\n",
        "\t\tmplot.xticks(rotation=90)\n",
        "\t\tmplot.show()\n",
        "\t\t# cf. print(nltk.ConfusionMatrix(gold_total, silver_total))"
      ],
      "metadata": {
        "id": "vkbR95bunhUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rest of the functions from the example: model training and the inference part"
      ],
      "metadata": {
        "id": "0q9EN-MDn7eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_training(data_path, verbose):\n",
        "\t\tprint(\"[I] Training an NB classifier...\")\n",
        "\t\tstart_time = datetime.datetime.now().replace(microsecond=0)\n",
        "\n",
        "\t\t# TRAINING\n",
        "\t\t# The final (production) model is trained by using all available data (train+test)\n",
        "\t\tnb = nltk.NaiveBayesClassifier.train(join_data(read_data(data_path)))\n",
        "\n",
        "\t\tend_time = datetime.datetime.now().replace(microsecond=0)\n",
        "\t\tprint(\"[I] Training time:\", end_time - start_time)\n",
        "\n",
        "\t\tif verbose:\n",
        "\t\t\t\tnb.show_most_informative_features(n=10) # Try with n=100\n",
        "\n",
        "\t\t# Save the model for later use\n",
        "\t\twith open(\"nb_classifier.pickle\", \"wb\") as dmp:\n",
        "\t\t\t\tpickle.dump(nb, dmp)\n",
        "\t\t\t\tprint(\"[I] NB classifier stored in a file\")"
      ],
      "metadata": {
        "id": "Bh7UQfU5oFvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference():\n",
        "\t\t# Load the pre-trained model\n",
        "\t\twith open(\"nb_classifier.pickle\", \"rb\") as dmp:\n",
        "\t\t\t\tnb = pickle.load(dmp)\n",
        "\t\t\t\tprint(\"[I] NB classifier loaded from a file\")\n",
        "\n",
        "\t\twhile True:\n",
        "\t\t\t\ttext = input(\"\\nEnter a text to classify: \")\n",
        "\t\t\t\tif len(text) == 0: break\n",
        "\n",
        "\t\t\t\t# Extract text features for classification\n",
        "\t\t\t\ttext_feat = vectorize_text(text)\n",
        "\t\t\t\tprint(\"\\nFeatures:\", text_feat.keys(), \"\\n\")\n",
        "\n",
        "\t\t\t\t# INFERENCE\n",
        "\t\t\t\t# Calculate a probability distribution over the classes\n",
        "\t\t\t\tprob_dist = nb.prob_classify(text_feat)\n",
        "\n",
        "\t\t\t\t# Return the probability distribution\n",
        "\t\t\t\tfor label in prob_dist.samples():\n",
        "\t\t\t\t\t\tprint(\"{0}: {1:.3f}\".format(classes[int(label)], prob_dist.prob(label)))\n",
        "\n",
        "\t\t\t\t# Return the most probable class\n",
        "\t\t\t\tprint(\"\\nPrediction:\", classes[int(prob_dist.max())])"
      ],
      "metadata": {
        "id": "y8uw-3GKoKMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execution of created functions. Base taken from the example, modified slightly to fit the changes in functions and make the model output the emotions instead of their numbers"
      ],
      "metadata": {
        "id": "ktDsUIEmoSaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise the stopword and word frequency lists\n",
        "initialise('stoplist.txt', 'freqlist.tsv')"
      ],
      "metadata": {
        "id": "x6e-8V0MopqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_validation2(\"train2.tsv\", \"test2.tsv\")"
      ],
      "metadata": {
        "id": "WmuyiVkzos8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the results with 5-repetition threshold. Decreasing the number leads to lower precision, increasing it results in lower recall."
      ],
      "metadata": {
        "id": "9fgaGOxrqvVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and save the final model\n",
        "run_training(\"train2.tsv\", True) # True=verbose"
      ],
      "metadata": {
        "id": "_b5ezpvBovnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the pre-trained model\n",
        "run_inference()"
      ],
      "metadata": {
        "id": "VNL2ARxKox2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, the created model shows worse results than the model presented in https://arxiv.org/pdf/2005.00547 (about 20% lower f1-score). It is hard for the model to recognize neutral class, because there are no words strongly associated with it. However, lexicon pruning helps improve the results: accuracy is 0.42 without it, 0.51 when pruning words that appear less than 5 times. Increasing the threshold leads to higher precision and lower recall, while decreasing it leads to higher recall and lower precision (to an extent). Overall accuracy and f1-score are maximized at 5-7 repetition threshold."
      ],
      "metadata": {
        "id": "rtm_wsrvqtA2"
      }
    }
  ]
}